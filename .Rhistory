class(loves_assocs)
hist(loves_assocs)
plot(loves_assocs)
freq
class(freq)
freq <- sort(colSums(as.matrix(dtm)),decreasing=TRUE)
class(freq)
freq
barplot(freq[1:50])
?barplot
barplot(freq[1:50], xlab = "term", ylab = "frequency",  col=topo.colors(12))
barplot(freq[1:50], xlab = "term", ylab = "frequency",  col=heat.colors(12))
barplot(freq[1:50], xlab = "term", ylab = "frequency",  col=heat.colors(50))
barplot(freq[1:50], xlab = "term", ylab = "frequency",  col=heat.colors(50, 0.8))
barplot(freq[1:30], xlab = "term", ylab = "frequency",  col=heat.colors(30))
barplot(freq[1:40], xlab = "term", ylab = "frequency",  col=heat.colors(40))
barplot(freq[1:1000], xlab = "term", ylab = "frequency",  col=heat.colors(1000))
barplot(freq[1:200], xlab = "term", ylab = "frequency",  col=heat.colors(200))
barplot(freq[1:100], xlab = "term", ylab = "frequency",  col=heat.colors(100))
barplot(freq[1:30], xlab = "term", ylab = "frequency",  col=heat.colors(30))
barplot(freq[1:20], xlab = "term", ylab = "frequency",  col=heat.colors(20))
source('~/angerhang.github.io/statsWithR/src/chaper2/style.R')
source('~/angerhang.github.io/statsWithR/src/style.R')
source('~/angerhang.github.io/statsWithR/src/style.R')
source('~/angerhang.github.io/statsWithR/src/style.R')
source('~/angerhang.github.io/statsWithR/src/chaper2/style.R')
source('~/angerhang.github.io/statsWithR/src/chaper2/style.R')
library(devtools)
install_github('rstudio/rmarkdown')
install.packages('knitr', repos = c('http://rforge.net', 'http://cran.rstudio.org'),
type = 'source')
install_github('jimhester/knitrBootstrap')
install.packages("twitteR")
library(twitteR)
setup_twitter_oauth("4tpxISsUHdWakcxH0M0VM3Dkl", "xfxHdjywUdy8CPFByHFuI0YKqhLxF2rK9fSHtmWnliMZGepqsP")
setup_twitter_oauth("4tpxISsUHdWakcxH0M0VM3Dkl", "xfxHdjywUdy8CPFByHFuI0YKqhLxF2rK9fSHtmWnliMZGepqsP")
setup_twitter_oauth("4tpxISsUHdWakcxH0M0VM3Dkl", "xfxHdjywUdy8CPFByHFuI0YKqhLxF2rK9fSHtmWnliMZGepqsP")
setup_twitter_oauth("4tpxISsUHdWakcxH0M0VM3Dkl", "xfxHdjywUdy8CPFByHFuI0YKqhLxF2rK9fSHtmWnliMZGepqsP")
tweets <- searchTwitter('#rstats', n=50)
tweet()
tweets
head(tweets)
tweets <- searchTwitter('#AI', n=40)
head(tweets)
jacobs <- getUser('Jacobs University')
jacobs <- getUser('Jacobs University')
jacobs <- getUser('Jacobs\ University')
jacobs <- getUser('Jacobs\ University')
jacobs <- getUser('jacobs_bremen')
jacobs$getDescription()
jacobs$getFavorites(n=10)
myDf <- twListToDF(tweets)
head(myDf)
jacobs_tweets <- userTimeline('jacobs_bremen')
jacobs_tweets[1:3]
availableTrendLocations()
trends = getTrends(2367105)
trends = getTrends(1)
head(trends)
friendships
friendships("angerhang", "jacobs_bremen")
dT <- getUser('realDonaldTrump')
follower <- dT$getFollowers()
dT <- userTimeline('realDonaldTrump')
?userTimeline
dT <- userTimeline('realDonaldTrump', n = 100)
n
head(dT)
dT <- userTimeline('realDonaldTrump', n = 3200)
library(tm)
dT_tm <- VCorpus(VectorSource(dT))
head(dT)
kk = unlist(dT)
head(kk)
dT_tm <- VCorpus(VectorSource(kK))
dT_tm <- VCorpus(VectorSource(kk))
rapply(dT, c)
kk = rapply(dT, c)
class(kk)
kk = do.call(c, dT)
class(kk)
kk = do.call("cbind", dT)
dT(1)
dT[1]
dT[1][1]
kk = unlist(dT)
kk = unlist(dT[1])
kk
str(kk)
kk$getFavoriteCount
kk$favoriteCount
kk[1]$favoriteCount
myDf <- ttwListToDF(dT)
myDf <- twListToDF(dT)
View(myDf)
plot(myDf$created, myDf$favoriteCount)
class(myDf$created)
myDf$date <- as.Date(myDf$created, '%Y-%d-%m')
as.Date()
?(as.Date)
?as.Date
myDf$created[1]
as.Date(myDf$created[1])
plot(myDf$created, myDf$favoriteCount)
plot.ts(myDf$created, myDf$favoriteCount)
plot(myDf$created, myDf$favoriteCount)
install.packages("tm.plugin.webmining")
library(tm)
library(tm.plugin.webmining)
jacobs <- Corpus(GoogleNewsSource("Germany"))
?GoogleNewsSource
corpus <- Corpus(GoogleNewsSource("Microsoft"))
corpus <- WebCorpus(GoogleNewsSource("Microsoft"))
class(corpus)
corpus
meta(corpus[[1]])
corpus[[1]]
corpus[[1]]$content
corpus[[2]]$content
corpus[[3]]$content
corpus[1]$content
corpus[1]$content
corpus[1]
inspect(Corpus())
inspect(corpus)
?extractContentDOM
extractContentDOM("http://www.economist.com/news/science-and-technology/21698641-new-way-understand-behaviour-ice-sheets-good-vibrations")
extractContentDOM("http://www.economist.com/news/science-and-technology/21698641-new-way-understand-behaviour-ice-sheets-good-vibrations")
my = url("http://www.economist.com/news/science-and-technology/21698641-new-way-understand-behaviour-ice-sheets-good-vibrations")
extractContentDOM(my)
test1 <- extractContentDOM("http://tecfa.unige.ch",0.1,FALSE)
test1
summary(corpus)
?extractContentDOM
climateArc <- extractContentDOM("http://www.economist.com/news/science-and-technology/21698641-new-way-understand-behaviour-ice-sheets-good-vibrations",0.5,FALSE)
climateArc
climateArc <- trimWhiteSpaces(climateArc)
climateArc
install.packages("RTextTools")
library('RTextTools')
data("USCongress")
my_matrix <- create_matrix(USCongress$text, language = "english", stemWords = TRUE,
removeSparseTerms = .999, removeNumbers = TRUE)
USCongress
View(USCongress)
summary(USCongress)
str(USCongress)
?USCongress
my_svm <- train_model(my_container, algorithm = "SVM")
my_nn <- train_model(my_container, algorithm = "NNET")
my_container <- create_container(my_matrix, USCongress$major, trainSize = 1:4000,
testSize = 4001:4449, virgin = FALSE)
my_svm <- train_model(my_container, algorithm = "SVM")
my_nn <- train_model(my_container, algorithm = "NNET")
svm_predictions <- classify_model(my_container, algorithm = "SVM")
svm_predictions <- classify_model(my_container, SVM)
svm_predictions <- classify_model(my_container, model = "SVM")
?classify_model
my_svm <- train_model(my_container, algorithm = "SVM")
svm_predictions <- classify_model(my_container, model = "SVM")
svm_predictions <- classify_model(my_container, model = my_svm)
my_rf <- train_model(my_container, algorithm = "RF")
?train_model
my_boost <- train_model(my_container, algorithm = "BOOSTING")
analytics <- create_analytics(my_container, cbind(svm_predictions))
summary(analytics)
install.packages("RMySQL")
---
mysqlconnection = dbConnect(MySQL(), user = 'root', password = '', dbname = 'sakila',
host = 'localhost')
# List the tables available in this database.
dbListTables(mysqlconnection)
library(DBI)
mysqlconnection = dbConnect(MySQL(), user = 'root', password = '', dbname = 'sakila',
host = 'localhost')
?dbConnect
library(RMySQL)
dbConnect(RMySQL::MySQL(),  user = 'root', password = '', dbname = 'sakila',
+                             host = 'localhost')
con <- dbConnect(RMySQL::MySQL(), dbname = "test")
con <- dbConnect(RMySQL::MySQL(), dbname = "test")
?"dbConnect"
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "test")
}
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "test", host = 'localhost')
}
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "test")
}
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "test")
}
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), group = "rs-dbi")
}
con <- dbConnect(RMySQL::MySQL(), dbname="mysql")
dbListTables(con)
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), group = "rs-dbi")
}
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), group = "rs-dbi")
}
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "mysql")
}
con <- dbConnect(RMySQL::MySQL(), dbname="mysql")
con <- dbConnect(RMySQL::MySQL(), dbname="test")
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), group="test")
}
con <- dbConnect(RMySQL::MySQL(), group="test")
dbListConnections()
dbListTables(conn = )
dbListTables(con )
dbListTables(con)
con <- dbConnect(RMySQL::MySQL(), group="test")
dbListTables(con)
dbDisconnect(con)
summary(con, verbose = TRUE)
con <- dbConnect(RMySQL::MySQL(), dbName="mysql")
con <- dbConnect(RMySQL::MySQL(), dbName="mysql")
dbListTables(con)
dbListFields(con, "table\user")
dbListFields(con, "user")
dbListTables(con)
d <- dbReadTable(con, "WL")
d <- dbReadTable(con, "time_zone")
d <- dbReadTable(con, "user")
View(d)
users <- dbReadTable(con, "user")
summary(users)
str(users)
user(1)
user[1]
users[1]
users[2]
class(users)
str(users)
options(warn=-1)
options(warn=0)
library(knitr)
?"knit"
dbGetQuery(con, "select * from mysql")
dbListTables(con)
dbGetQuery(con, "select * from user")
dbGetQuery(con, "select * from time_zone")
dbGetQuery(con, "select * from Host")
dbGetQuery(con, "select * from event")
dbGetQuery(con, "select * from servers")
dbGetQuery(con, "select * from time_zone_name")
summary(con)
summary(con, verbose = TRUE)
dbListConnections(MySQL())
summary(MySQL())
summary(MySQL(), verbose = TRUE)
dbGetRowCount(con)
show(con)
?show
myUsers <- dbGetQuery(con, "select * from user")
dbGetRowCount(myUsers)
rs <- dbSendQuery(con, "SELECT * FROM mysql WHERE user == root")
rs <- dbSendQuery(con, "SELECT * FROM mysql WHERE user = root")
rs <- dbSendQuery(con, "SELECT * FROM user WHERE user = root")
users <- dbReadTable(con, "user")
users
rs <- dbSendQuery(con, "SELECT * FROM user WHERE User like 'root'")
dbHasCompleted(rs)
dbGetStatement(rs)
dbHasCompleted(rs)
dbGetInfo(rs)
dbClearResult(rs)
shiny::runApp('HPIHack')
shiny::runApp('HPIHack')
library(jsonlite)
getwd()
setwd("HPIHack/")
test <- fromJSON("latest-1000.json", flatten = TRUE)
View(test)
summary(test)
colnames(test)
mynames <- colnames(test)
mynames
options(max.print = 99999999)
mynames
test <- fromJSON("myjson.json", flatten = TRUE)
test <- fromJSON("latest-1000.json", flatten = TRUE)
View(test)
features <- c("id", "labels.en.language", "linked")
reducedData <- subset(test, select = features)
test[1]$labels.en.value
test$labels.en.language[1]
test$labels.en.value[1]
features <- c("id", "labels.en.value", "linked")
reducedData <- subset(test, select = features)
test <- fromJSON("myjson.json", flatten = TRUE)
test <- fromJSON("myjson.json", flatten = TRUE)
test <- fromJSON("linked.json", flatten = TRUE)
test$linked
features <- c("id", "labels.en.value", "linked")
reducedData <- subset(test, select = features)
View(reducedData)
View(test)
View(test)
View(reducedData)
# import it into dataframe
test <- fromJSON("linked.json", flatten = TRUE)
test$linked[1]
test$linked[2]
test$linked[3]
test$linked[4]
test$linked[5]
test$linked[6]
test$linked[7]
# Extract important features
features <- c("id", "labels.en.value", "linked")
reducedData <- subset(test, select = features)
View(reducedData)
View(test)
colnames(test)
options(max.print=5.5E5)
colnames(test)
grep("id", colnames(test))
test[. 215]
test[, 215]
test[, 215][1]
test[,216][1]
test[,216]
grep("id", colnames(test))
test[,217]
test[,608]
testNames <- colnames(test)
testNames[c(2  215  216  217  608  609  610 1166 1167 1168 1427 1428 1429 1442 1443 1444 1827 1828 2269 2270 3431)]
getIndex <- grep("id", colnames(test))
a = c(1, 2, 4, 5)
a[1, 4]
a[c(1, 2, 4)]
testNames[getIndex]
getIndex <- grep("ID", colnames(test))
testNames
View(test)
firstRow = teset[1, ]
firstRow = test[1, ]
getIndex <- grep("323", firstRow)
firstRow
getIndex <- grep("claims", firstRow)
getIndex <- grep("claims", colnames(test))
getIndex <- grep("claims", colnames(test))
getIndex
getIndex <- grep("claims", firstRow)
test$claims.P50[1]
test$claims.P50
# import it into dataframe
test <- fromJSON("linked.json", flatten = TRUE)
# Extract important features
features <- c("id", "labels.en.value", "linked")
reducedData <- subset(test, select = features)
View(reducedData)
View(test)
test$linked
test$linked[1]
test$linked[2]
unlist(test$linked[2])
library(dplyr)
# import it into dataframe
test <- fromJSON("linked.json", flatten = TRUE)
# Extract important features
features <- c("id", "labels.en.value", "linked")
reducedData <- subset(test, select = features)
View(reducedData)
reducedData$linked
reducedData$linked[2]
reducedData$linked[7]
newList <- apply(mylist, function(x) unlist(x))
newList <- xapply(mylist, function(x) unlist(x) )
newList <- tapply(mylist, function(x) unlist(x) )
mylist <- reducedData$linked
newList <- tapply(mylist, function(x) unlist(x) )
reducedData$linked[7]
list(reducedData$linked[7])
unlist(reducedData$linked[7])
newList <- tapply(mylist, function(x) unlist(x) )
newList <- unlist(mylist)
newList <- lapply(mylist, function (x) unlist(x))
newList <- newList[2:length(newList)]
newList <- c(newList, c())
reducedData$linked = newList
newList <- c(newList, NULL)
newList <- c(newList, c( ))
oddList <- NULL
newList <- c(newList, oddList)
oddList <- c()
newList <- c(newList, oddList)
newList <- c(newList, list(NULL))
library(dplyr)
reducedData$linked = newList
View(reducedData)
ids <- reducedData$id
ids <- lapply(ids, function (x) substr(x, 2, nrow(x)))
class(reducedData$id)
ids <- reducedData$id
ids <- lapply(ids, function (x) substr(x, 2, nrow(x)))
ids <- reducedData$id
ids <- lapply(ids, function (x) substr(x, 2, nrow(x)))
ids <- lapply(ids, function (x) substr(x, 2, nchar(x)))
reducedData$id = ids
View(reducedData)
getwd()
shiny::runApp('visuApp')
reducedData[1,]
src <- c()
target <- c()
for (i in 1:length(reducedData)){
current <- reducedData[i ,]
edges <- current$linked
for (j in 1:length(edges)){
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
src <- c()
target <- c()
for (i in 1:nrow(reducedData)){
current <- reducedData[i ,]
edges <- current$linked
for (j in 1:length(edges)){
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
# Make the edges
src <- c()
target <- c()
for (i in 1:nrow(reducedData)){
current <- reducedData[i ,]
edges <- unlist(current$linked)
for (j in 1:length(edges)){
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
src <- c()
target <- c()
for (i in 1:nrow(reducedData)){
current <- reducedData[i ,]
edges <- unlist(current$linked)
for (j in 1:length(edges)){
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
reducedData$id = as.character(reducedData$id)
src <- c()
target <- c()
for (i in 1:nrow(reducedData)){
current <- reducedData[i ,]
edges <- unlist(current$linked)
for (j in 1:length(edges)){
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
summary(target)
reducedData$id = as.character(reducedData$id)
src <- c()
target <- c()
for (i in 1:nrow(reducedData)) {
current <- reducedData[i ,]
edges <- unlist(current$linked)
for (j in 1:length(edges)) {
if (length(edges) !=) {
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
}
# Make the edges
reducedData$id = as.character(reducedData$id)
src <- c()
target <- c()
for (i in 1:nrow(reducedData)) {
current <- reducedData[i ,]
edges <- unlist(current$linked)
for (j in 1:length(edges)) {
if (length(edges) != 0) {
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
}
networkData <- data.frame(src, target)
simpleNetwork(networkData)
max(reducedData$id)
summary(reducedData$id)
max = max(as.numeric(reducedData$id))
src <- c()
target <- c()
for (i in 1:nrow(reducedData)) {
current <- reducedData[i ,]
edges <- unlist(current$linked)
for (j in 1:length(edges)) {
if (length(edges) != 0 || edges[j] <= max) {
src <- c(src, current$id)
target <- c(target, edges[j])
}
}
}
networkData <- data.frame(src, target)
simpleNetwork(networkData)
shiny::runApp('visuApp')
